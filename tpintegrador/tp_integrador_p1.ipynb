{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creo el archivo '**custom_file**'. Este, es una copia del archivo '**ar-airports.csv**' y el que vamos a modificar. En la copia, genero una nueva columna en el encabezado llamada '**elevation_name**' que tendrá como contenido: \"bajo\", \"medio\" o \"alto\", según la elevación de cada aeropuerto (elevation_ft). Si el campo '**elevation_ft**' no contiene ningún valor se completará con un '**-**'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import csv\n",
    "\n",
    "airport_file_route = Path('./datasets/ar-airports.csv')\n",
    "custom_file_route = Path('./custom_datasets/ar-airports.csv')\n",
    "\n",
    "with open(airport_file_route, 'r', encoding= 'utf-8') as airport_file, open(custom_file_route, 'w', encoding= 'utf-8') as custom_file:\n",
    "    airport_reader = csv.reader(airport_file)\n",
    "    writer = csv.writer(custom_file)\n",
    "\n",
    "    header = next(airport_reader)\n",
    "    header.append('elevation_name')\n",
    "    writer.writerow(header)\n",
    "\n",
    "    elevation = 6\n",
    "\n",
    "    for line in airport_reader:\n",
    "        if line[elevation]:\n",
    "            if int(line[elevation]) <= 131:\n",
    "                line.append('bajo')\n",
    "            elif 131 < int(line[elevation]) <= 903: \n",
    "                line.append('medio')\n",
    "            else:\n",
    "                line.append('alto')\n",
    "        else:\n",
    "            line.append('-')  \n",
    "        writer.writerow(line)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agrego una columna llamada '**prov_name**', donde se incluirá el nombre de la provincia correspondiente a cada aeropuerto. Esta información se obtendrá consultando los nombres de las ciudades en el dataset (E). Si no se encuentra la ciudad en el dataset(E) se completara con '**-**'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m reader \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mreader(custom_file)\n\u001b[0;32m      7\u001b[0m writer \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mwriter(file_definitive)\n\u001b[1;32m----> 9\u001b[0m header \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m header\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprov_name\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m writer\u001b[38;5;241m.\u001b[39mwriterow(header)\n",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "argentina_file_route = Path('./datasets/ar.csv')\n",
    "file_route_definitive = Path('./custom_datasets/ar-airports_with_provs.csv')\n",
    "\n",
    "with open(argentina_file_route, encoding= 'utf-8') as argentina_file, open(custom_file_route, 'r', encoding= 'utf-8') as custom_file, open(file_route_definitive, 'w', encoding= 'utf-8') as file_definitive:\n",
    "    argentina_reader = csv.reader(argentina_file)\n",
    "    reader = csv.reader(custom_file)\n",
    "    writer = csv.writer(file_definitive)\n",
    "\n",
    "    header = next(reader)\n",
    "    header.append('prov_name')\n",
    "    writer.writerow(header)\n",
    "\n",
    "    municipality = 13\n",
    "    city = 0\n",
    "    admin_name = 5\n",
    "    region_name = 10\n",
    "\n",
    "    for custom_row in reader:\n",
    "        city_name = custom_row[municipality] \n",
    "        argentina_file.seek(0)\n",
    "        found = False \n",
    "        for argentina_row in argentina_reader:\n",
    "            if argentina_row[city] == city_name:\n",
    "                province_name = argentina_row[admin_name]  \n",
    "                custom_row.append(province_name)\n",
    "                found = True\n",
    "                break\n",
    "        if not found:   \n",
    "            custom_row.append('-')      \n",
    "        writer.writerow(custom_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copio el archivo '**Conectividad_internet.csv**', donde  se realizará un reemplazo en las celdas que contengan el carácter '-' con la palabra 'NO'. Ademas se agregara una columna llamada '**posee_conectividad**' : El valor será NO si todos los campos ADSL, CABLEMODEM, DIALUP,FIBRAOPTICA, SATELITAL, WIRELESS, TELEFONIAFIJA, 3G y 4G poseen el valor --. Caso contrario el valor será SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_file_route = Path('./datasets/Conectividad_Internet.csv')\n",
    "custom_connection = Path('./custom_datasets/Conectividad_Internet.csv')\n",
    "\n",
    "with open(connection_file_route, encoding= 'utf-8') as connection_file, open(custom_connection, 'w', encoding= 'utf-8') as custom_file:\n",
    "    connection_reader = csv.reader(connection_file)\n",
    "    writer = csv.writer(custom_file)\n",
    "\n",
    "    header = next(connection_reader)\n",
    "    header.append('posee_conectividad')\n",
    "    writer.writerow(header)\n",
    "\n",
    "    for line in connection_reader: ## tipo lista\n",
    "        if 'SI' in line[4:13]:\n",
    "            line.append('SI')\n",
    "        else:\n",
    "            line.append('NO')\n",
    "        line = ['NO' if element == '--' else element for element in line]\n",
    "        writer.writerow(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### En el dataset de Lagos (C), se crearán nuevas columnas que indican los coordenadas en formato GMS(grados,minutos y segundos)y GD(grados decimales). \n",
    "#### En el dataset de Lagos (C), se creará una nueva columna llamada 'Sup Tamaño' que contendrá datos cualitativos indicando el tamaño de cada lago en función de su superficie en kilómetros cuadrados (km²). Esta columna se completará con las palabras: \"chico\", \"medio\" o \"grande\", según los siguientes criterios:\n",
    "- ##### a. Lagos con una superficie menor o igual a 17 km² serán clasificados como \"chico\".\n",
    "- ##### b. Lagos con una superficie mayor que 17 km² y menor o igual a 59 km² serán clasificados como \"medio\".\n",
    "- ##### c. Lagos con una superficie mayor a 59 km² serán clasificados como \"grande\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lakes_file_route = Path('./datasets/lagos_arg.csv')\n",
    "custom_lakes = Path('./custom_datasets/lagos_arg.csv')\n",
    "\n",
    "import module\n",
    "\n",
    "with open(lakes_file_route) as lakes_file, open(custom_lakes, 'w') as custom_file:\n",
    "    lakes_reader = csv.reader(lakes_file)\n",
    "    writer = csv.writer(custom_file)\n",
    "\n",
    "    header = next(lakes_reader)\n",
    "    header[5] = 'Latitud GMS'\n",
    "    header = header + ['Longitud GMS','Latitud GD','Longitud GD','Sup TamaÃ±o']\n",
    "    writer.writerow(header)\n",
    "\n",
    "    surface = 2\n",
    "    coordenadas = 5\n",
    "    for line in lakes_reader:\n",
    "        \n",
    "        campos = line[coordenadas].split()\n",
    "        line[5] = campos[0]\n",
    "        line = line + [campos[1]]\n",
    "\n",
    "        campos = module.convert_to_dd(campos)\n",
    "\n",
    "        line = line + [campos[0],campos[1]]\n",
    "        #-----------------------------------------\n",
    "        if line[surface]:\n",
    "            if int(line[surface]) <= 17:\n",
    "                line.append('chico')\n",
    "            elif 17 < int(line[surface]) <= 59: \n",
    "                line.append('medio')\n",
    "            else:\n",
    "                line.append('grande')\n",
    "        else:\n",
    "            line.append('-')  \n",
    "\n",
    "        writer.writerow(line) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Reemplazo los valores \"///\" y \"-\" por 0. Y tambien agrego una columna donde dice el porcentaje de poblacion en situacion de calle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "poblation_file_route = Path('./datasets/c2022_tp_c_resumen_adaptado.csv')\n",
    "custom_poblation = Path('./custom_datasets/c2022_tp_c_resumen_adaptado.csv')\n",
    "\n",
    "with open(poblation_file_route, encoding= 'utf-8') as poblation_file, open(custom_poblation, 'w', encoding= 'utf-8') as custom_file:\n",
    "    poblation_reader = csv.reader(poblation_file)\n",
    "    writer = csv.writer(custom_file)\n",
    "\n",
    "    header = next(poblation_reader)\n",
    "    header.append('Porcentaje de población en situación de calle')\n",
    "    writer.writerow(header)\n",
    "\n",
    "    homeless_people = 4\n",
    "    people = 1\n",
    "\n",
    "    for line in poblation_reader:\n",
    "        line = ['0' if element == '///' or element == '-' else element for element in line]\n",
    "        \n",
    "        line.append('% '+str(int(line[homeless_people])/int(line[people])*100))\n",
    "        writer.writerow(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
